# Jarvis Terminal

Un asistente de IA personal para tu terminal, inspirado en Jarvis. Combina una interfaz de usuario textual (TUI), reconocimiento de voz, s√≠ntesis de voz y la potencia de m√∫ltiples proveedores de IA para ofrecer una experiencia de asistente conversacional directamente en tu l√≠nea de comandos.

<!--  -->

## ‚ú® Caracter√≠sticas Principales

- **Interfaz de Usuario en Terminal (TUI)**: Una interfaz limpia y moderna construida con [Textual](https://github.com/Textualize/textual) que muestra la conversaci√≥n, el estado del sistema y logs de depuraci√≥n.
- **Entrada Dual (Voz y Texto)**: Interact√∫a con Jarvis hablando o escribiendo directamente en la terminal.
- **Detecci√≥n de Palabra de Activaci√≥n**: Activa a Jarvis con "Oye Jarvis" (configurable) para dar comandos por voz sin necesidad de tocar el teclado.
- **Reconocimiento de Voz (STT)**: Utiliza `faster-whisper` para una transcripci√≥n de voz a texto r√°pida y precisa, con soporte para ejecuci√≥n en GPU.
- **S√≠ntesis de Voz (TTS)**: Elige entre una voz local y r√°pida con `pyttsx3` o voces de alta calidad en la nube con `ElevenLabs`.
- **Soporte Multi-IA**: Con√©ctate a diferentes modelos de lenguaje grandes (LLMs) seg√∫n tus preferencias y necesidades. Proveedores soportados:
    - Groq (Llama3)
    - OpenAI (GPT-3.5-Turbo, GPT-4, etc.)
    - Google (Gemini Pro)
    - Anthropic (Claude 3 Haiku)
- **Memoria Persistente**: Jarvis puede recordar informaci√≥n entre sesiones. P√≠dele que recuerde algo y lo guardar√° en `memory.json`.
- **Sistema de Correcciones**: Mejora la precisi√≥n del reconocimiento de voz a√±adiendo correcciones personalizadas en `corrections.json` para palabras o frases que Whisper no transcribe bien.
- **Altamente Configurable**: Personaliza casi todos los aspectos del asistente, desde las palabras de activaci√≥n hasta los umbrales de audio, a trav√©s de un √∫nico archivo `config.json`.

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

- Python 3.8 o superior.
- `git` para clonar el repositorio.
- **`ffmpeg`**: Es necesario para el procesamiento de audio de Whisper.
    - **Windows**: `choco install ffmpeg` o desc√°rgalo desde su web oficial y a√±√°delo al PATH.
    - **macOS**: `brew install ffmpeg`
    - **Linux (Debian/Ubuntu)**: `sudo apt update && sudo apt install ffmpeg`

### 1. Clonar el Repositorio

```bash
git clone https://github.com/ivanvihe/jarvis_terminal.git
cd jarvis_terminal
```

### 2. Instalar Dependencias

Se recomienda crear un entorno virtual:

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

Luego, instala las dependencias necesarias:

```bash
pip install -r requirements.txt
```

El archivo `requirements.txt` debe contener:

```txt
requests
pyttsx3
faster-whisper
torch
pyaudio
numpy
textual
psutil
```

*Nota sobre `torch`*: Si tienes una GPU NVIDIA compatible, puedes instalar la versi√≥n con soporte CUDA para un rendimiento mucho mayor en el STT. Consulta las instrucciones oficiales de PyTorch.

*Nota sobre `pyaudio`*: En Linux, puede que necesites instalar `portaudio` primero: `sudo apt-get install portaudio19-dev`.

### 3. Configuraci√≥n de Archivos Necesarios

#### Archivo `config.json` (Obligatorio)

Debes crear un archivo llamado `config.json` en la ra√≠z del proyecto. Este archivo controla el comportamiento de Jarvis. Ejemplo y explicaci√≥n de cada par√°metro:

```json
{
  "debug_ai": false,                    // Activa logs de depuraci√≥n para IA
  "debug_tts": false,                   // Activa logs de depuraci√≥n para TTS
  "debug_stt": false,                   // Activa logs de depuraci√≥n para STT
  "voice_input_enabled": true,          // Habilita/deshabilita entrada por voz
  "sample_rate": 16000,                 // Frecuencia de muestreo de audio (Hz)
  "channels": 1,                        // N√∫mero de canales de audio (1=mono, 2=stereo)
  "volume_threshold": 0.08,             // Umbral de volumen para detectar voz
  "vad_mode": "simple",                // Modo de detecci√≥n de voz: "simple" o avanzado
  "wake_words": ["oye jarvis", "hey jarvis", "jarvis"], // Palabras de activaci√≥n
  "wake_word": "jarvis",               // Palabra de activaci√≥n principal
  "wake_duration": 4,                   // Duraci√≥n m√°xima (segundos) para escuchar la palabra de activaci√≥n
  "command_duration": 8,                // Duraci√≥n m√°xima (segundos) para escuchar el comando tras la activaci√≥n
  "interactive_mode_duration": 10,      // Tiempo (segundos) en modo interactivo tras activaci√≥n
  "whisper_model_size": "small",       // Tama√±o del modelo Whisper: "tiny", "base", "small", "medium", "large-v3"
  "use_gpu": true,                      // Usa GPU si est√° disponible
  "speech_threshold_multiplier": 1.5,   // Multiplicador para el umbral de detecci√≥n de voz
  "silence_duration": 2.5,              // Segundos de silencio para finalizar grabaci√≥n
  "min_recording_duration": 1.0,        // Duraci√≥n m√≠nima de grabaci√≥n (segundos)
  "min_file_size": 1000,                // Tama√±o m√≠nimo del archivo de audio (bytes)
  "whisper_no_speech_threshold": 0.6,   // Umbral de no-speech para Whisper
  "whisper_temperature": 0.0,           // Temperatura para la transcripci√≥n de Whisper

  "ai_provider": "groq",               // "groq", "openai", "gemini", "claude"
  "tts": "local",                      // "local" (pyttsx3) o "elevenlabs"

  "groq_api_key": "...",
  "openai_api_key": "...",
  "gemini_api_key": "...",
  "claude_api_key": "...",

  "elevenlabs": {
    "api_key": "...",                  // Solo si usas ElevenLabs
    "voice_id": "..."
  },

  "local_tts": {
    "voice": "Helena",                 // Nombre de la voz local (depende del sistema)
    "rate": 180                         // Velocidad de la voz
  },

  "integrations": {
    "gmail": {
      "enabled": false,
      "type": "mcp",
      "mcp_server": {
        "command": "python",
        "args": ["-m", "mcp_gmail_server"],
        "env": {
          "GMAIL_CREDENTIALS": "credentials.json"
        }
      },
      "capabilities": ["email", "send mail", "read mail", "check inbox"],
      "keywords": ["correo", "email", "gmail", "enviar mensaje"]
    },
    "alexa": {
      "enabled": false,
      "type": "api",
      "api_config": {
        "skill_id": "...",
        "client_id": "...",
        "client_secret": "..."
      },
      "capabilities": ["smart home", "alexa", "control devices"],
      "keywords": ["alexa", "luces", "dispositivos", "casa inteligente"]
    },
    "windows_run": {
      "enabled": true,
      "type": "simple",
      "apps": {
        "emule": "C:\\Program Files (x86)\\eMule\\emule.exe"
      },
      "capabilities": ["abrir", "ejecutar", "lanzar", "inicia", "run", "open"],
      "keywords": ["emule", "notepad", "firefox"]
    },
    "windows_session": { "enabled": true, "type": "simple" }
  }
}
```

**Notas sobre par√°metros avanzados:**
- `channels`: 1 para mono, 2 para est√©reo (normalmente 1).
- `vad_mode`: "simple" o puedes implementar otros modos si ampl√≠as el sistema.
- `wake_duration` y `command_duration`: controlan los tiempos m√°ximos de escucha.
- `interactive_mode_duration`: tiempo de espera en modo interactivo tras la activaci√≥n.
- `speech_threshold_multiplier`, `min_recording_duration`, `min_file_size`, `whisper_no_speech_threshold`, `whisper_temperature`: par√°metros avanzados para ajustar la sensibilidad y calidad del reconocimiento de voz.
- `integrations`: permite definir integraciones externas (Gmail, Alexa, Windows, etc.) con sus propios par√°metros.

## ‚ñ∂Ô∏è Uso

Una vez configurado, ejecuta el asistente desde la ra√≠z del proyecto:

```bash
python jarvis.py
```

- **Para hablar**: Di la palabra de activaci√≥n (p. ej., "Oye Jarvis") seguida de tu comando.
- **Para escribir**: Simplemente escribe tu comando en la parte inferior de la pantalla y presiona Enter.
- **Para salir**: Escribe `salir` o `adios`, o presiona `Ctrl+C`.

## üèóÔ∏è Estructura del Proyecto

- `jarvis.py`: El punto de entrada principal. Orquesta la inicializaci√≥n y los bucles de entrada.
- `ai.py`: L√≥gica para comunicarse con las diferentes APIs de los proveedores de IA.
- `stt.py`: Grabaci√≥n de audio y transcripci√≥n con `faster-whisper`.
- `tts.py`: S√≠ntesis de voz para el motor local o ElevenLabs.
- `jarvis_ui.py`: Interfaz de usuario con `textual`.
- `ui_bridge.py`: Puente entre backend (Jarvis) y frontend (TUI).
- `config_loader.py`: Carga y acceso a los valores de `config.json`.
- `memory.py`: Clase `Memory` para cargar y guardar el historial de la conversaci√≥n.
- `corrections.py`: Carga y aplica las correcciones del archivo `corrections.json`.
- `integrations/`: Integraciones adicionales (ej. Gmail, Windows, etc).

---

**¬°Listo! Jarvis Terminal est√° preparado para ser tu asistente personal en la terminal.**