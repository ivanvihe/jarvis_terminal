# Jarvis Terminal

Un asistente de IA personal para tu terminal, inspirado en Jarvis. Combina una interfaz de usuario textual (TUI), reconocimiento de voz, s√≠ntesis de voz y la potencia de m√∫ltiples proveedores de IA para ofrecer una experiencia de asistente conversacional directamente en tu l√≠nea de comandos.

<!--  -->

## ‚ú® Caracter√≠sticas Principales

- **Interfaz de Usuario en Terminal (TUI)**: Una interfaz limpia y moderna construida con [Textual](https://github.com/Textualize/textual) que muestra la conversaci√≥n, el estado del sistema y logs de depuraci√≥n.
- **Entrada Dual (Voz y Texto)**: Interact√∫a con Jarvis hablando o escribiendo directamente en la terminal.
- **Detecci√≥n de Palabra de Activaci√≥n**: Activa a Jarvis con "Oye Jarvis" (configurable) para dar comandos por voz sin necesidad de tocar el teclado.
- **Reconocimiento de Voz (STT)**: Utiliza `faster-whisper` para una transcripci√≥n de voz a texto r√°pida y precisa, con soporte para ejecuci√≥n en GPU.
- **S√≠ntesis de Voz (TTS)**: Elige entre una voz local y r√°pida con `pyttsx3` o voces de alta calidad en la nube con `ElevenLabs`.
- **Soporte Multi-IA**: Con√©ctate a diferentes modelos de lenguaje grandes (LLMs) seg√∫n tus preferencias y necesidades. Proveedores soportados:
    - Groq (Llama3)
    - OpenAI (GPT-3.5-Turbo, GPT-4, etc.)
    - Google (Gemini Pro)
    - Anthropic (Claude 3 Haiku)
- **Memoria Persistente**: Jarvis puede recordar informaci√≥n entre sesiones. P√≠dele que recuerde algo y lo guardar√° en `memory.json`.
- **Sistema de Correcciones**: Mejora la precisi√≥n del reconocimiento de voz a√±adiendo correcciones personalizadas en `corrections.json` para palabras o frases que Whisper no transcribe bien.
- **Altamente Configurable**: Personaliza casi todos los aspectos del asistente, desde las palabras de activaci√≥n hasta los umbrales de audio, a trav√©s de un √∫nico archivo `config.json`.

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

- Python 3.8 o superior.
- `git` para clonar el repositorio.
- **`ffmpeg`**: Es necesario para el procesamiento de audio de Whisper.
    - **Windows**: `choco install ffmpeg` o desc√°rgalo desde su web oficial y a√±√°delo al PATH.
    - **macOS**: `brew install ffmpeg`
    - **Linux (Debian/Ubuntu)**: `sudo apt update && sudo apt install ffmpeg`

### 1. Clonar el Repositorio

```bash
git clone https://github.com/your-username/jarvis_terminal.git
cd jarvis_terminal
```

### 2. Instalar Dependencias

Se recomienda crear un entorno virtual:

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

Luego, instala las dependencias necesarias. Puedes crear un archivo `requirements.txt` con el siguiente contenido y ejecutar `pip install -r requirements.txt`:

```txt
# requirements.txt
requests
pyttsx3
faster-whisper
torch
pyaudio
numpy
textual
psutil
```

*Nota sobre `torch`*: Si tienes una GPU NVIDIA compatible, puedes instalar la versi√≥n con soporte CUDA para un rendimiento mucho mayor en el STT. Consulta las instrucciones oficiales de PyTorch.

*Nota sobre `pyaudio`*: En Linux, puede que necesites instalar `portaudio` primero: `sudo apt-get install portaudio19-dev`.

### 3. Crear el archivo `config.json`

Crea un archivo llamado `config.json` en la ra√≠z del proyecto. Puedes usar este ejemplo como plantilla y modificarlo seg√∫n tus necesidades.

```json
{
  "voice_input_enabled": true,
  "sample_rate": 16000,
  "volume_threshold": 0.08,
  "wake_words": ["oye jarvis", "hey jarvis", "jarvis"],
  "whisper_model_size": "small",
  "use_gpu": true,
  "tts": "local",
  "ai_provider": "groq",
  "debug_ai": false,
  "debug_tts": false,
  "debug_stt": false,
  "silence_duration": 1.5,

  "elevenlabs": {
    "api_key": "TU_API_KEY_DE_ELEVENLABS",
    "voice_id": "ID_DE_LA_VOZ_QUE_QUIERES_USAR"
  },

  "local_tts": {
    "voice": "helena",
    "rate": 180
  },

  "groq_api_key": "TU_API_KEY_DE_GROQ",
  "openai_api_key": "TU_API_KEY_DE_OPENAI",
  "gemini_api_key": "TU_API_KEY_DE_GEMINI",
  "claude_api_key": "TU_API_KEY_DE_CLAUDE"
}
```

**Explicaci√≥n de claves importantes:**
- `ai_provider`: Elige entre `"groq"`, `"openai"`, `"gemini"`, `"claude"`.
- `tts`: Elige entre `"local"` o `"elevenlabs"`.
- `whisper_model_size`: Modelos disponibles: `"tiny"`, `"base"`, `"small"`, `"medium"`, `"large-v3"`. Modelos m√°s grandes son m√°s precisos pero m√°s lentos y consumen m√°s recursos.
- `use_gpu`: Ponlo en `true` si tienes una GPU NVIDIA compatible y has instalado la versi√≥n correcta de `torch`.
- Rellena las claves API (`..._api_key`) para los servicios que quieras usar.

### 4. (Opcional) Crear `corrections.json`

Si notas que el reconocimiento de voz falla consistentemente con ciertas palabras (por ejemplo, nombres propios o t√©rminos t√©cnicos), puedes crear un archivo `corrections.json` para solucionarlo.

Ejemplo de `corrections.json`:

```json
{
  "faster whisper": "faster-whisper",
  "textualais": "textualize",
  "grook": "groq"
}
```
El sistema reemplazar√° autom√°ticamente la clave (texto incorrecto) por el valor (texto correcto) en la transcripci√≥n.

## ‚ñ∂Ô∏è Uso

Una vez configurado, ejecuta el asistente desde la ra√≠z del proyecto:

```bash
python jarvis.py
```

- **Para hablar**: Di la palabra de activaci√≥n (p. ej., "Oye Jarvis") seguida de tu comando.
- **Para escribir**: Simplemente escribe tu comando en el campo de entrada en la parte inferior de la pantalla y presiona Enter.
- **Para salir**: Escribe `salir` o `adios`, o presiona `Ctrl+C`.

## üèóÔ∏è Estructura del Proyecto

- `jarvis.py`: El punto de entrada principal. Orquesta la inicializaci√≥n y los bucles de entrada.
- `ai.py`: Contiene la l√≥gica para comunicarse con las diferentes APIs de los proveedores de IA.
- `stt.py`: Gestiona la grabaci√≥n de audio y la transcripci√≥n con `faster-whisper`.
- `tts.py`: Gestiona la s√≠ntesis de voz para el motor local o ElevenLabs.
- `jarvis_ui.py`: Define la interfaz de usuario con `textual`.
- `ui_bridge.py`: Act√∫a como un puente para comunicar de forma segura entre el backend (Jarvis) y el frontend (la TUI).
- `config_loader.py`: Carga y proporciona acceso a los valores de `config.json`.
- `memory.py`: Implementa la clase `Memory` para cargar y guardar el historial de la conversaci√≥n.
- `corrections.py`: Carga y aplica las correcciones del archivo `corrections.json`.